{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Python Scientific Data Analysis\n",
    "## Course's Final Project\n",
    "### Barak Daniel - 204594329"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Installations needed for the program to run:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy\n",
    "#!pip install pandas\n",
    "#!pip install seaborn\n",
    "#!pip install matplotlib\n",
    "#!pip install seaborn\n",
    "#!pip install sklearn\n",
    "#!pip install scipy\n",
    "#!pip install pydotplus\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import sklearn as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import pydotplus\n",
    "import random"
   ]
  },
  {
   "source": [
    "# Intro\n",
    "\n",
    "### Overview\n",
    "This project is about targetted marketing, in the data set given we have 'customer' as each row of data, and the features can tell us about the customer's status in general (age, marriage, etc..) and hes shopping behavior.\n",
    "In this section of the project I will go over the data set and the goal to try and understand the whole process before starting the actual work on the data.\n",
    "\n",
    "### So what exactly is targetted marketing?\n",
    "Targeting in marketing is a strategy that breaks a large market into smaller segments to concentrate on a specific group of customers within that audience. It defines a segment of customers based on their unique characteristics and focuses solely on serving them.\n",
    "Instead of trying to reach an entire market, a brand uses target marketing to put their energy into connecting with a specific, defined group within that market.\n",
    "So for this reason I'll break down all the features in the given dataset ('customers3.csv'), and understand them.\n",
    "\n",
    "\n",
    "### Feature's data breadown\n",
    "The following features are included in the data set given in 'customes3.csv':\n",
    "- ID - Unique ID to each customer\n",
    "- Gender - The gender of the customer\n",
    "- Ever_Marries - Indicates if the customer was married\n",
    "- Age - The age of the customer\n",
    "- Graduated - Has the customer graduated high school\n",
    "- Profession - The profession of the customer\n",
    "- Work_Experience - The number of years of the customer's expirence in his profession\n",
    "- Spending_Score - The spending habits of the customer classified to 3 categories\n",
    "- Family_Size - The number of family members the customer has in his household\n",
    "- Shop_Day - The day of the week which the customer is shopping on the most\n",
    "- Shop_Other - Normalized measure of customer deviation from average store customer spending on non specified products\n",
    "- Shop_Dairy - Normalized measure of customer deviation from average store customer spending on dairy products\n",
    "- Shop_Household: Normalized measure of customer deviation from average store customer spending on household products\n",
    "- Shop_Meat - Normalized measure of customer deviation from average store customer spending on meat products\n",
    "- Group - The target group which the customer belongs to\n",
    "\n",
    "### Feature's type breakdown\n",
    "- ID - Numerical discrete (Integer)\n",
    "- Gender - Categorical (Male/Female)\n",
    "- Ever_Marries - Categorical nominal (Yes/No)\n",
    "- Age - Numerical continuous (Integer)\n",
    "- Graduated - Categorical (Yes/No)\n",
    "- Profession - Categorical nominal\n",
    "- Work_Experience - Numerical discrete (Integer)\n",
    "- Spending_Score - Categorical ordinal (Low/average/High)\n",
    "- Family_Size - Numerical discrete (Integer)\n",
    "- Shop_Day - Categorical ordinal (Sunday, Monday, ..., Saturday)\n",
    "- Shop_Other - Numerical continuous (Double)\n",
    "- Shop_Dair - Numerical continuous (Double)\n",
    "- Shop_Household - Numerical continuous (Double)\n",
    "- Shop_Meat -Numerical continuous (Double)\n",
    "- Group - Categorical nominal"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('customers3.csv')\n",
    "count = df.count()\n",
    "\n",
    "print(\"The number of rows is: {}\".format(len(df.index)))\n",
    "print(\"The number of columns is: {}\".format(len(df.columns)))\n",
    "print(\"The number of cells is: {}\".format(len(df.index) * len(df.columns)))\n",
    "print(\"The number of cells with concrete values is: {}\".format(count.sum()))\n",
    "print(\"The number of cells without concrete values is: {}\\n\".format(len(df.index) * len(df.columns) - count.sum()))\n",
    "\n",
    "print(\"\\nThe number of concrete values for each feature:\")\n",
    "df.count()\n"
   ]
  },
  {
   "source": [
    "### The size of the data set is:\n",
    "- 8120 rows of customer's data (+1 for the headers of each column)\n",
    "- 15 columns for the features\n",
    "- 8120*15 = 121,8000 cells, but we can see that not all of them has concrete values.\n",
    "\n",
    "### Missing values:\n",
    "After watching the dataset and trying to understand it, I have also encountered many cells with missing data values.\n",
    "After reading the dataset a transformation of this Nan values is needed, for each feature with missing data, I'll examine it and understand which of the methods is the best to deal with those values (Mode, Mean, Median, Removal, etc..).\n",
    "\n",
    "### Other types of missing values:\n",
    "A validation for the values that are not missing must be made, after going through the features, the options are numeric value which is out of the range as given with feature definition, a numeric value that cannot be negative, etc...\n",
    "\n",
    "After going through out the dataset, those are the features needed to be fixed:\n",
    "- Shop_Day - Must contain values of 1 to 7 but there are values out of this range therefore it will be filled by the same method as all the feature values\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Initial Data Analysis\n",
    "\n",
    "As we saw above, there are a lot of missing values and categorical values we want to transform before we can alanyze the data completely.\n",
    "In this section of the project I will deal with those values, for each feature a check for the accuracy of the model will be taken and by that I can make the decision what was the best method for the feature."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The first feature to handle missing data will be 'Gender', since we have less than 60 missing values and its binary the best method to do it is to check their distributions over the data set and then fill them with this distributions.\n"
   ],
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male = 0\n",
    "female = 0\n",
    "for index,row in df.iterrows():\n",
    "    if(row['Gender'] == 'Male'):\n",
    "        male += 1\n",
    "    elif(row['Gender'] == 'Female'):\n",
    "        female += 1\n",
    "\n",
    "print(\"Female precentage\", female/(male+female))\n",
    "print(\"Male precentage\", male/(male+female))"
   ]
  },
  {
   "source": [
    "So we can see now that females represents ~45.25% of the rows in the data set and Males are ~54.75% .\n",
    "Now we fill the missing values with this distribution:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nans = df['Gender'].isna()\n",
    "length = sum(nans)\n",
    "replacement = random.choices(['Male', 'Female'], weights=[.5475, .4525], k=length)\n",
    "df.loc[nans,'Gender'] = replacement\n",
    "\n",
    "df.Gender.count()"
   ]
  },
  {
   "source": [
    "The next feature I'll be dealing with is Ever_Married which is also a binary answer of yes or no.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "married = 0\n",
    "notmarried = 0\n",
    "for index,row in df.iterrows():\n",
    "    if(row['Ever_Married'] == 'Yes'):\n",
    "        married += 1\n",
    "    elif(row['Ever_Married'] == 'No'):\n",
    "        notmarried += 1\n",
    "\n",
    "\n",
    "married_list = [\"Yes\", \"No\"]\n",
    "df[\"Ever_Married_Transformed\"] = pd.Categorical(df.Ever_Married, ordered=True, categories=married_list).codes + 1\n",
    "group_list = [\"A\", \"B\", \"C\", \"D\"]\n",
    "df[\"Group_Transformed\"] = pd.Categorical(df.Group, ordered=True, categories=group_list).codes + 1\n",
    "\n",
    "print(df[\"Group_Transformed\"].corr(df[\"Ever_Married_Transformed\"]))\n",
    "df.drop(['Ever_Married_Transformed', 'Group_Transformed'], axis=1)\n",
    "\n",
    "print(\"Percentage of married = \", (married/(married+notmarried)))\n",
    "print(\"Percentage of married = \", (notmarried/(married+notmarried)))\n"
   ]
  },
  {
   "source": [
    "The correlation to the group is low and therefore I can use the same method as I did in 'Gender'."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nans = df['Ever_Married'].isna()\n",
    "length = sum(nans)\n",
    "replacement = random.choices(['Yes', 'No'], weights=[.5859, .4141], k=length)\n",
    "df.loc[nans,'Ever_Married'] = replacement\n",
    "\n",
    "df.Ever_Married.count()"
   ]
  },
  {
   "source": [
    "The next feature to deal with is 'Age', first I'll check some of the feature's data like the range and mean.\n",
    "Afterwards I fill the df with the values in the better method."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_list = [\"A\", \"B\", \"C\", \"D\"]\n",
    "df[\"Group_Transformed\"] = pd.Categorical(df.Group, ordered=True, categories=group_list).codes + 1\n",
    "\n",
    "print(df[\"Group_Transformed\"].corr(df[\"Age\"]))\n",
    "\n",
    "ageMin = df.Age.min()\n",
    "ageMax = df.Age.max()\n",
    "ageMean = df.Age.mean()\n",
    "ageMedian = df.Age.median()\n",
    "\n",
    "print(\"\\nAge aggregations:\\nMean = {}\\nMedian = {}\".format(ageMean, ageMedian))\n",
    "print(\"Min age is: {}  --- Max age is: {}\\n\".format(ageMin, ageMax))\n",
    "\n",
    "df[\"Mean_Age\"] = df.Age.fillna(ageMean)\n",
    "df[\"Median_Age\"] = df.Age.fillna(ageMedian)\n",
    "\n",
    "\n",
    "print(\"Corr with mean: \", df[\"Group_Transformed\"].corr(df[\"Mean_Age\"]))\n",
    "print(\"Corr with median: \", df[\"Group_Transformed\"].corr(df[\"Median_Age\"]))"
   ]
  },
  {
   "source": [
    "As we can see, both of the values are nearly the same, but we will still prefer the median for the better correlation even if it is only slightly higher."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Age = df.Median_Age\n",
    "df = df.drop(['Group_Transformed', \"Mean_Age\", \"Median_Age\"], axis=1)\n",
    "\n",
    "df.Age.count()"
   ]
  },
  {
   "source": [
    "The next feature will be Graduated which missing a few values, so like the other binary features I have dealt with above, I'll do the same here."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = 0\n",
    "ungrad = 0\n",
    "for index,row in df.iterrows():\n",
    "    if(row['Graduated'] == 'Yes'):\n",
    "        grad += 1\n",
    "    elif(row['Graduated'] == 'No'):\n",
    "        ungrad += 1\n",
    "\n",
    "print(\"Graduated precentage\", ungrad/(grad+ungrad))\n",
    "print(\"Haven't graduated precentage\", grad/(grad+ungrad))\n",
    "\n",
    "nans = df['Graduated'].isna()\n",
    "length = sum(nans)\n",
    "replacement = random.choices(['Yes', 'No'], weights=[.3781, .6219], k=length)\n",
    "df.loc[nans,'Graduated'] = replacement\n",
    "\n",
    "df.Graduated.count()"
   ]
  },
  {
   "source": [
    "The next feature is Profession, the difference from the features we dealt with already is that this feature is Categorical nominal which the set of his values is not finite, therefore to fill this column and not lose the data from the rest of the rows, I will fill the values with Mode."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proMode = df.Profession.mode()\n",
    "df[\"Profession\"] = df.Age.fillna(proMode)"
   ]
  },
  {
   "source": [
    "Now the feature to be dealt with is Work_Expirence, because there is the Age col, maybe here we can fill the missing values with deductive imputation, so now I'll check their corr and decide how to fill this feature."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Age.corr(df.Work_Experience)"
   ]
  },
  {
   "source": [
    "Because the corr is low, using the Age feature won't be good enough for filling those values, now I'll check the mathematical operation that can be done."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_list = [\"A\", \"B\", \"C\", \"D\"]\n",
    "df[\"Group_Transformed\"] = pd.Categorical(df.Group, ordered=True, categories=group_list).codes + 1\n",
    "\n",
    "print(df[\"Group_Transformed\"].corr(df[\"Work_Experience\"]))\n",
    "\n",
    "workMin = df.Work_Experience.min()\n",
    "workMax = df.Work_Experience.max()\n",
    "workMean = df.Work_Experience.mean()\n",
    "workMedian = df.Work_Experience.median()\n",
    "\n",
    "print(\"\\nAge aggregations:\\nMean = {}\\nMedian = {}\".format(workMean, workMedian))\n",
    "print(\"Min work exp is: {}  --- Max work exp is: {}\\n\".format(workMin, workMax))\n",
    "\n",
    "df[\"Mean_work\"] = df.Work_Experience.fillna(workMean)\n",
    "df[\"Median_work\"] = df.Work_Experience.fillna(workMedian)\n",
    "\n",
    "\n",
    "print(\"Corr with mean: \", df[\"Group_Transformed\"].corr(df[\"Mean_work\"]))\n",
    "print(\"Corr with median: \", df[\"Group_Transformed\"].corr(df[\"Median_work\"]))\n",
    "\n",
    "df[\"Work_Experience\"] = df.Work_Experience.fillna(workMean)\n",
    "df = df.drop(['Group_Transformed', \"Mean_work\", \"Median_work\"], axis=1)\n",
    "\n",
    "print(df.Work_Experience.count())"
   ]
  },
  {
   "source": [
    "As we can see in the above, the correlation that is most fitted here is filling the missing values with Mean.\n",
    "\n",
    "Now the next feature is \"family size\", for that feature I will test Mode, Median and Mean.\n",
    "For the mean option I will round the value of the mean so there will be a valid family size value."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_list = [\"A\", \"B\", \"C\", \"D\"]\n",
    "df[\"Group_Transformed\"] = pd.Categorical(df.Group, ordered=True, categories=group_list).codes + 1\n",
    "\n",
    "print(df[\"Group_Transformed\"].corr(df[\"Family_Size\"]))\n",
    "\n",
    "familyMean = round(df.Family_Size.mean())\n",
    "familyMedian = df.Family_Size.median()\n",
    "familyMode = df.Family_Size.mode()[0]\n",
    "\n",
    "print(\"\\nAge aggregations:\\nMean = {}\\nMedian = {}\\nMode = {}\\n\".format(familyMean, familyMedian, familyMode))\n",
    "\n",
    "df[\"Mean_family\"] = df.Family_Size.fillna(familyMean)\n",
    "df[\"Median_family\"] = df.Family_Size.fillna(familyMedian)\n",
    "df[\"Mode_family\"] = df.Family_Size.fillna(familyMode)\n",
    "\n",
    "\n",
    "print(\"Corr with mean: \", df[\"Group_Transformed\"].corr(df[\"Mean_family\"]))\n",
    "print(\"Corr with median: \", df[\"Group_Transformed\"].corr(df[\"Median_family\"]))\n",
    "print(\"Corr with mode: \", df[\"Group_Transformed\"].corr(df[\"Mode_family\"]))\n",
    "\n",
    "df[\"Family_Size\"] = df.Family_Size.fillna(familyMean)\n",
    "df = df.drop(['Group_Transformed', \"Mean_family\", \"Median_family\", \"Mode_family\"], axis=1)\n",
    "\n",
    "print(df.Family_Size.count())"
   ]
  },
  {
   "source": [
    "Both mean and median gave the same result and got better correlation than mode, that is why I choose their value to fill the \"Family_Size\" feature."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "For the next feature, \"Shop_Day\", before filling the missing values I need to deal with the wrong values the feaure is containing:\n",
    "Must contain values of 1 to 7 but there are values out of this range."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.Shop_Day.unique())"
   ]
  },
  {
   "source": [
    "The values that needs to be dealt with first are 0 and 22"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_Shop_Day = df.Shop_Day\n",
    "for index, value in enumerate(temp_Shop_Day):\n",
    "    if(value == 0 or value == 22):\n",
    "        temp_Shop_Day[index] = np.nan\n",
    "\n",
    "df.Shop_Day = temp_Shop_Day\n",
    "print(df.Shop_Day.unique())"
   ]
  },
  {
   "source": [
    "Now I can fill the missing values by checking the best mathematical operation without wrong values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_list = [\"A\", \"B\", \"C\", \"D\"]\n",
    "df[\"Group_Transformed\"] = pd.Categorical(df.Group, ordered=True, categories=group_list).codes + 1\n",
    "\n",
    "print(df[\"Group_Transformed\"].corr(df[\"Shop_Day\"]))\n",
    "\n",
    "dayMean = round(df.Shop_Day.mean())\n",
    "dayMedian = df.Shop_Day.median()\n",
    "dayMode = df.Shop_Day.mode()[0]\n",
    "\n",
    "print(\"\\nAge aggregations:\\nMean = {}\\nMedian = {}\\nMode = {}\\n\".format(dayMean, dayMedian, dayMode))\n",
    "\n",
    "df[\"Mean_day\"] = df.Shop_Day.fillna(dayMean)\n",
    "df[\"Median_day\"] = df.Shop_Day.fillna(dayMedian)\n",
    "df[\"Mode_day\"] = df.Shop_Day.fillna(dayMode)\n",
    "\n",
    "\n",
    "print(\"Corr with mean: \", df[\"Group_Transformed\"].corr(df[\"Mean_day\"]))\n",
    "print(\"Corr with median: \", df[\"Group_Transformed\"].corr(df[\"Median_day\"]))\n",
    "print(\"Corr with mode: \", df[\"Group_Transformed\"].corr(df[\"Mode_day\"]))\n",
    "\n",
    "df[\"Shop_Day\"] = df.Shop_Day.fillna(dayMean)\n",
    "df = df.drop(['Group_Transformed', \"Mean_day\", \"Median_day\", \"Mode_day\"], axis=1)\n",
    "\n",
    "print(df.Shop_Day.count())"
   ]
  },
  {
   "source": [
    "As we can see above the Mean filling option is better than median and mode which are sharing the same value, Therefore I chose to use it."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Moving on to the next feature, \"Shop_Diary\", I will check all the fitting mathematical operations as well."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_list = [\"A\", \"B\", \"C\", \"D\"]\n",
    "df[\"Group_Transformed\"] = pd.Categorical(df.Group, ordered=True, categories=group_list).codes + 1\n",
    "\n",
    "print(df[\"Group_Transformed\"].corr(df[\"Shop_Dairy\"]))\n",
    "\n",
    "dairyMean = df.Shop_Dairy.mean()\n",
    "dairyMedian = df.Shop_Dairy.median()\n",
    "dairyMode = df.Shop_Dairy.mode()[0]\n",
    "\n",
    "print(\"\\nAge aggregations:\\nMean = {}\\nMedian = {}\\nMode = {}\\n\".format(dairyMean, dairyMedian, dairyMode))\n",
    "\n",
    "df[\"Mean_dairy\"] = df.Shop_Dairy.fillna(dairyMean)\n",
    "df[\"Median_dairy\"] = df.Shop_Dairy.fillna(dairyMedian)\n",
    "df[\"Mode_dairy\"] = df.Shop_Dairy.fillna(dairyMode)\n",
    "\n",
    "\n",
    "print(\"Corr with mean: \", df[\"Group_Transformed\"].corr(df[\"Mean_dairy\"]))\n",
    "print(\"Corr with median: \", df[\"Group_Transformed\"].corr(df[\"Median_dairy\"]))\n",
    "print(\"Corr with mode: \", df[\"Group_Transformed\"].corr(df[\"Mode_dairy\"]))\n",
    "\n",
    "df[\"Shop_Dairy\"] = df.Shop_Dairy.fillna(dairyMean)\n",
    "df = df.drop(['Group_Transformed', \"Mean_dairy\", \"Median_dairy\", \"Mode_dairy\"], axis=1)\n",
    "\n",
    "print(df.Shop_Dairy.count())"
   ]
  },
  {
   "source": [
    "The mean and median are pretty close in their correlation to the group, still mean is higher so That is why I chose to use it here as well. \n",
    "\n",
    "For the next 2 feature's, \"Shop_Household\" and \"Shop_Meat\", I will use the same method as in Dairy "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_list = [\"A\", \"B\", \"C\", \"D\"]\n",
    "df[\"Group_Transformed\"] = pd.Categorical(df.Group, ordered=True, categories=group_list).codes + 1\n",
    "\n",
    "print(df[\"Group_Transformed\"].corr(df[\"Shop_Household\"]))\n",
    "\n",
    "HouseholdMean = df.Shop_Household.mean()\n",
    "HouseholdMedian = df.Shop_Household.median()\n",
    "HouseholdMode = df.Shop_Household.mode()[0]\n",
    "\n",
    "print(\"\\nAge aggregations:\\nMean = {}\\nMedian = {}\\nMode = {}\\n\".format(HouseholdMean, HouseholdMedian, HouseholdMode))\n",
    "\n",
    "df[\"Mean_Household\"] = df.Shop_Household.fillna(HouseholdMean)\n",
    "df[\"Median_Household\"] = df.Shop_Household.fillna(HouseholdMedian)\n",
    "df[\"Mode_Household\"] = df.Shop_Household.fillna(HouseholdMode)\n",
    "\n",
    "\n",
    "print(\"Corr with mean: \", df[\"Group_Transformed\"].corr(df[\"Mean_Household\"]))\n",
    "print(\"Corr with median: \", df[\"Group_Transformed\"].corr(df[\"Median_Household\"]))\n",
    "print(\"Corr with mode: \", df[\"Group_Transformed\"].corr(df[\"Mode_Household\"]))\n",
    "\n",
    "df[\"Shop_Household\"] = df.Shop_Household.fillna(HouseholdMean)\n",
    "df = df.drop(['Group_Transformed', \"Mean_Household\", \"Median_Household\", \"Mode_Household\"], axis=1)\n",
    "\n",
    "print(df.Shop_Household.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_list = [\"A\", \"B\", \"C\", \"D\"]\n",
    "df[\"Group_Transformed\"] = pd.Categorical(df.Group, ordered=True, categories=group_list).codes + 1\n",
    "\n",
    "print(df[\"Group_Transformed\"].corr(df[\"Shop_Meat\"]))\n",
    "\n",
    "MeatMean = round(df.Shop_Meat.mean())\n",
    "MeatMedian = df.Shop_Meat.median()\n",
    "MeatMode = df.Shop_Meat.mode()[0]\n",
    "\n",
    "print(\"\\nAge aggregations:\\nMean = {}\\nMedian = {}\\nMode = {}\\n\".format(MeatMean, MeatMedian, MeatMode))\n",
    "\n",
    "df[\"Mean_Household\"] = df.Shop_Meat.fillna(MeatMean)\n",
    "df[\"Median_Household\"] = df.Shop_Meat.fillna(MeatMedian)\n",
    "df[\"Mode_Household\"] = df.Shop_Meat.fillna(MeatMode)\n",
    "\n",
    "\n",
    "print(\"Corr with mean: \", df[\"Group_Transformed\"].corr(df[\"Mean_Household\"]))\n",
    "print(\"Corr with median: \", df[\"Group_Transformed\"].corr(df[\"Median_Household\"]))\n",
    "print(\"Corr with mode: \", df[\"Group_Transformed\"].corr(df[\"Mode_Household\"]))\n",
    "\n",
    "df[\"Shop_Meat\"] = df.Shop_Meat.fillna(MeatMean)\n",
    "df = df.drop(['Group_Transformed', \"Mean_Household\", \"Median_Household\", \"Mode_Household\"], axis=1)\n",
    "\n",
    "print(df.Shop_Meat.count())"
   ]
  },
  {
   "source": [
    "Both \"Shop_Household\" and \"Shop_Meat\" will get the best result by filling with the mean value of the feature."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}